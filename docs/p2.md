# Project 2: User Programs

## Preliminaries

>Fill in your name and email address.

Rundong Yang <3096842671@qq.com>

>If you have any preliminary comments on your submission, notes for the TAs, please give them here.

We claim to get **100** points out of 100 in this project.


>Please cite any offline or online sources you consulted while preparing your submission, other than the Pintos documentation, course text, lecture notes, and course staff.

(void)

## Argument Passing

#### DATA STRUCTURES

>A1: Copy here the declaration of each new or changed struct or struct member, global or static variable, typedef, or enumeration.  Identify the purpose of each in 25 words or less.

(none)

#### ALGORITHMS

>A2: Briefly describe how you implemented argument parsing.  How do you arrange for the elements of argv[] to be in the right order?
>How do you avoid overflowing the stack page?

When parsing file name in load function, we use an array `argv` to record each arguments. Unfortunately,
this design choice makes it impossible to have more than 10 arguments. For the stack pointer grow downward, 
we do not have to worry about page overflow.


#### RATIONALE

>A3: Why does Pintos implement strtok_r() but not strtok()?

Well, my implementation uses neither `strtok_r` nor `strtok`. Instead, I write my own version
of them.

>A4: In Pintos, the kernel separates commands into a executable name and arguments.  In Unix-like systems, the shell does this separation.  Identify at least two advantages of the Unix approach.

Advantages:
<ul>
  <li> The kernel does less job, hence reduces latency; </li>
  <li> Allows the shell to do some tasks(i.e. do not have to start a new process!) </li>
</ul>


## System Calls

#### DATA STRUCTURES

>B1: Copy here the declaration of each new or changed struct or struct member, global or static variable, typedef, or enumeration.  Identify the purpose of each in 25 words or less.

In [filesys/filesys.c](../src/filesys/filesys.c):
```c
/** File system lock */
static struct lock fs_lock;
```
The lock protects the file system and forces serial execution on disk.

In [userprog/process.h](../src/userprog/process.h)
```c
struct file;
/** Metadata of a user process(put on stack) */
struct process_meta
  { 
    char           *argv;       /**< Position of argv */
    struct file    *ofile[MAX_FILE];
                                /**< File descriptor table */
    struct file    *executable; /**< Executable; must close on process_exit. */
  };
```
The metadata contains information such as executable files, process name, file descriptor table.
Pointer to this struct is stored in thread struct.

In [userprog/syscall.c](../src/userprog/syscall.c)
```c
/** list of implemented system calls */
static syscall_executor_t syscall_executors[] = 
  {
    [SYS_HALT] halt_executor,
    [SYS_EXIT] exit_executor,
    [SYS_EXEC] exec_executor,
    [SYS_WAIT] wait_executor,
    [SYS_CREATE] create_executor,
    [SYS_REMOVE] remove_executor,
    [SYS_OPEN] open_executor,
    [SYS_FILESIZE] filesize_executor,
    [SYS_READ] read_executor,
    [SYS_WRITE] write_executor,
    [SYS_SEEK] seek_executor,
    [SYS_TELL] tell_executor,
    [SYS_CLOSE] close_executor,
  };
```
This array serves as a mapping from system call id to system call executor.


>B2: Describe how file descriptors are associated with open files. Are file descriptors unique within the entire OS or just within a single process?

In my implementation file descriptors are associated with a single process; not the entire system.
File descriptors(short for **fd** in later parts of this doc) are integer index to the array of
(pointer to) file structs, hence can lead us to the actual file. See 
[userprog/process.h](../src/userprog/process.h).


#### ALGORITHMS

>B3: Describe your code for reading and writing user data from the kernel.

Steps of reading user data: See `copy_from_user` implemented in [userprog/syscall.c](../src/userprog/syscall.c).
<ol>
  <li>Lookup the page table, if page is missing, exit(-1). </li>
  <li>Else read page by page, copying user data into kernel buffer.</li>
</ol>

Writing user data follows similar process. See `copy_to_user` implemented in 
[userprog/syscall.c](../src/userprog/syscall.c).

>B4: Suppose a system call causes a full page (4,096 bytes) of data
>to be copied from user space into the kernel.  What is the least
>and the greatest possible number of inspections of the page table
>(e.g. calls to pagedir_get_page()) that might result?  What about
>for a system call that only copies 2 bytes of data?  Is there room
>for improvement in these numbers, and how much?

The least possible number: 1; the greatest possible number is 2 as long as 
the page is continuous. 
If only 2 bytes are copied, least: 1, greatest: 2(if the 2 bytes lie across different page)
I don't think there's room for improvements.

>B5: Briefly describe your implementation of the "wait" system call
>and how it interacts with process termination.

When a process asks for "wait" system call, we first lookup the process list
to ensure that wanted process exists; and block the thread. When the thread exit 
by calling "exit" or interrupt, we lookup the list of blocked thread, and decide 
which to unblock.


>B6: Any access to user program memory at a user-specified address
>can fail due to a bad pointer value.  Such accesses must cause the
>process to be terminated.  System calls are fraught with such
>accesses, e.g. a "write" system call requires reading the system
>call number from the user stack, then each of the call's three
>arguments, then an arbitrary amount of user memory, and any of
>these can fail at any point.  This poses a design and
>error-handling problem: how do you best avoid obscuring the primary
>function of code in a morass of error-handling?  Furthermore, when
>an error is detected, how do you ensure that all temporarily
>allocated resources (locks, buffers, etc.) are freed?  In a few
>paragraphs, describe the strategy or strategies you adopted for
>managing these issues.  Give an example.

Strategies:
<ul>
  <li>All system calls that lead to page fault does not hold a lock when reading/writing 
  user memory, i.e. will not need to track locks. </li>
  <li>When thread_exit is called, we automatically close the file(s) opened by the 
  killed process. </li>
  <li>In a call to thread_exit, all memory of that process will be freed, as done in thread_exit.</li>
</ul>

#### SYNCHRONIZATION

>B7: The "exec" system call returns -1 if loading the new executable
>fails, so it cannot return before the new executable has completed
>loading.  How does your code ensure this?  How is the load
>success/failure status passed back to the thread that calls "exec"?

In my implementation, processes that is trying to execute other processes
are blocked and put on a list; when the loading completes(either success or failure),
we scan the list and unblock the process that is waiting for the return value from 
**exec**.


>B8: Consider parent process P with child process C.  How do you
>ensure proper synchronization and avoid race conditions when P
>calls wait(C) before C exits?  After C exits?  How do you ensure
>that all resources are freed in each case?  How about when P
>terminates without waiting, before C exits?  After C exits?  Are
>there any special cases?


These problem has the same answer: **turn of interrupts**, which makes
race condition impossible.

#### RATIONALE

>B9: Why did you choose to implement access to user memory from the
>kernel in the way that you did?

Straight-forward, easy to check invalid pointers and page faults; make interrupt
handler do less work. But this requires extra work to get right(i.e. a lot of edge cases
and synchronization bugs need to be considered).


>B10: What advantages or disadvantages can you see to your design
>for file descriptors?

As far as I'm concerned, my "fd" implementation has the following advantages:
<ul>
  <li>Good isolation between different processes; </li>
  <li>fd are process-independent, which allows a process to open significantly more files
  than other implementation. </li>
  <li> Easy to determine when files should be closed; </li>
</ul>

It should be noted that my implementation also has some disadvantages:
<ul>
  <li> May lead to data racing on files; e.g. two process trying to write to the 
  same file; </li>
  <li> File object cannot be easily shared between processed; </li>
</ul>


>B11: The default tid_t to pid_t mapping is the identity mapping.
>If you changed it, what advantages are there to your approach?

No. I haven't change such design, it's still identity mapping.